{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "url = \"Automobile_data.csv\"\n",
    "from pyspark import SparkFiles\n",
    "sc.addFile(url)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symboling: integer (nullable = true)\n",
      " |-- normalized-losses: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- fuel-type: string (nullable = true)\n",
      " |-- aspiration: string (nullable = true)\n",
      " |-- num-of-doors: string (nullable = true)\n",
      " |-- body-style: string (nullable = true)\n",
      " |-- drive-wheels: string (nullable = true)\n",
      " |-- engine-location: string (nullable = true)\n",
      " |-- wheel-base: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- width: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- curb-weight: integer (nullable = true)\n",
      " |-- engine-type: string (nullable = true)\n",
      " |-- num-of-cylinders: string (nullable = true)\n",
      " |-- engine-size: integer (nullable = true)\n",
      " |-- fuel-system: string (nullable = true)\n",
      " |-- bore: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- compression-ratio: double (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- peak-rpm: string (nullable = true)\n",
      " |-- city-mpg: integer (nullable = true)\n",
      " |-- highway-mpg: integer (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(SparkFiles.get(\"Automobile_data.csv\"), header=True, inferSchema= True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+\n",
      "|symboling|normalized-losses|make       |fuel-type|aspiration|num-of-doors|body-style |drive-wheels|engine-location|wheel-base|length|width|height|curb-weight|engine-type|num-of-cylinders|engine-size|fuel-system|bore|stroke|compression-ratio|horsepower|peak-rpm|city-mpg|highway-mpg|price|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+\n",
      "|3        |?                |alfa-romero|gas      |std       |two         |convertible|rwd         |front          |88.6      |168.8 |64.1 |48.8  |2548       |dohc       |four            |130        |mpfi       |3.47|2.68  |9.0              |111       |5000    |21      |27         |13495|\n",
      "|3        |?                |alfa-romero|gas      |std       |two         |convertible|rwd         |front          |88.6      |168.8 |64.1 |48.8  |2548       |dohc       |four            |130        |mpfi       |3.47|2.68  |9.0              |111       |5000    |21      |27         |16500|\n",
      "|1        |?                |alfa-romero|gas      |std       |two         |hatchback  |rwd         |front          |94.5      |171.2 |65.5 |52.4  |2823       |ohcv       |six             |152        |mpfi       |2.68|3.47  |9.0              |154       |5000    |19      |26         |16500|\n",
      "|2        |164              |audi       |gas      |std       |four        |sedan      |fwd         |front          |99.8      |176.6 |66.2 |54.3  |2337       |ohc        |four            |109        |mpfi       |3.19|3.4   |10.0             |102       |5500    |24      |30         |13950|\n",
      "|2        |164              |audi       |gas      |std       |four        |sedan      |4wd         |front          |99.4      |176.6 |66.4 |54.3  |2824       |ohc        |five            |136        |mpfi       |3.19|3.4   |8.0              |115       |5500    |18      |22         |17450|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symboling: string (nullable = true)\n",
      " |-- normalized-losses: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- fuel-type: string (nullable = true)\n",
      " |-- aspiration: string (nullable = true)\n",
      " |-- num-of-doors: string (nullable = true)\n",
      " |-- body-style: string (nullable = true)\n",
      " |-- drive-wheels: string (nullable = true)\n",
      " |-- engine-location: string (nullable = true)\n",
      " |-- wheel-base: string (nullable = true)\n",
      " |-- length: string (nullable = true)\n",
      " |-- width: string (nullable = true)\n",
      " |-- height: string (nullable = true)\n",
      " |-- curb-weight: string (nullable = true)\n",
      " |-- engine-type: string (nullable = true)\n",
      " |-- num-of-cylinders: string (nullable = true)\n",
      " |-- engine-size: string (nullable = true)\n",
      " |-- fuel-system: string (nullable = true)\n",
      " |-- bore: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- compression-ratio: string (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- peak-rpm: string (nullable = true)\n",
      " |-- city-mpg: string (nullable = true)\n",
      " |-- highway-mpg: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(SparkFiles.get(\"Automobile_data.csv\"), header=True, inferSchema= False)\n",
    "df.printSchema()\n",
    "# if inferSchema set False all columns from csv are set to string\n",
    "# else their type(int,float ) from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symboling: integer (nullable = true)\n",
      " |-- normalized-losses: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- fuel-type: string (nullable = true)\n",
      " |-- aspiration: string (nullable = true)\n",
      " |-- num-of-doors: string (nullable = true)\n",
      " |-- body-style: string (nullable = true)\n",
      " |-- drive-wheels: string (nullable = true)\n",
      " |-- engine-location: string (nullable = true)\n",
      " |-- wheel-base: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- width: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- curb-weight: integer (nullable = true)\n",
      " |-- engine-type: string (nullable = true)\n",
      " |-- num-of-cylinders: string (nullable = true)\n",
      " |-- engine-size: integer (nullable = true)\n",
      " |-- fuel-system: string (nullable = true)\n",
      " |-- bore: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- compression-ratio: double (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- peak-rpm: string (nullable = true)\n",
      " |-- city-mpg: integer (nullable = true)\n",
      " |-- highway-mpg: integer (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- symboling: integer (nullable = true)\n",
      " |-- normalized-losses: string (nullable = true)\n",
      " |-- make: float (nullable = true)\n",
      " |-- fuel-type: float (nullable = true)\n",
      " |-- aspiration: float (nullable = true)\n",
      " |-- num-of-doors: float (nullable = true)\n",
      " |-- body-style: string (nullable = true)\n",
      " |-- drive-wheels: string (nullable = true)\n",
      " |-- engine-location: string (nullable = true)\n",
      " |-- wheel-base: float (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- width: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- curb-weight: integer (nullable = true)\n",
      " |-- engine-type: string (nullable = true)\n",
      " |-- num-of-cylinders: string (nullable = true)\n",
      " |-- engine-size: integer (nullable = true)\n",
      " |-- fuel-system: float (nullable = true)\n",
      " |-- bore: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- compression-ratio: double (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- peak-rpm: string (nullable = true)\n",
      " |-- city-mpg: integer (nullable = true)\n",
      " |-- highway-mpg: integer (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "df_string = sqlContext.read.csv(SparkFiles.get(\"Automobile_data.csv\"), header=True, inferSchema=  True)\n",
    "df_string.printSchema()\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "# List of continuous features\n",
    "CONTI_FEATURES  = ['make', 'fuel-type','num-of-doors', 'aspiration', 'wheel-base', 'fuel-system']\n",
    "# Convert the type\n",
    "df_string = convertColumn(df_string, CONTI_FEATURES, FloatType())\n",
    "# Check the dataset\n",
    "df_string.printSchema()\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "#stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"newlabel\")\n",
    "#model = stringIndexer.fit(df)\n",
    "#df = model.transform(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symboling: integer (nullable = true)\n",
      " |-- normalized-losses: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- fuel-type: string (nullable = true)\n",
      " |-- aspiration: string (nullable = true)\n",
      " |-- num-of-doors: string (nullable = true)\n",
      " |-- body-style: string (nullable = true)\n",
      " |-- drive-wheels: string (nullable = true)\n",
      " |-- engine-location: string (nullable = true)\n",
      " |-- wheel-base: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- width: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- curb-weight: integer (nullable = true)\n",
      " |-- engine-type: string (nullable = true)\n",
      " |-- num-of-cylinders: string (nullable = true)\n",
      " |-- engine-size: integer (nullable = true)\n",
      " |-- fuel-system: string (nullable = true)\n",
      " |-- bore: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- compression-ratio: double (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- peak-rpm: string (nullable = true)\n",
      " |-- city-mpg: integer (nullable = true)\n",
      " |-- highway-mpg: integer (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- symboling: integer (nullable = true)\n",
      " |-- normalized-losses: string (nullable = true)\n",
      " |-- make: float (nullable = true)\n",
      " |-- fuel-type: float (nullable = true)\n",
      " |-- aspiration: float (nullable = true)\n",
      " |-- num-of-doors: float (nullable = true)\n",
      " |-- body-style: string (nullable = true)\n",
      " |-- drive-wheels: string (nullable = true)\n",
      " |-- engine-location: string (nullable = true)\n",
      " |-- wheel-base: float (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- width: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- curb-weight: integer (nullable = true)\n",
      " |-- engine-type: string (nullable = true)\n",
      " |-- num-of-cylinders: string (nullable = true)\n",
      " |-- engine-size: integer (nullable = true)\n",
      " |-- fuel-system: float (nullable = true)\n",
      " |-- bore: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- compression-ratio: double (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- peak-rpm: string (nullable = true)\n",
      " |-- city-mpg: integer (nullable = true)\n",
      " |-- highway-mpg: integer (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- symboling: string (nullable = true)\n",
      " |-- normalized-losses: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- fuel-type: string (nullable = true)\n",
      " |-- aspiration: string (nullable = true)\n",
      " |-- num-of-doors: string (nullable = true)\n",
      " |-- body-style: string (nullable = true)\n",
      " |-- drive-wheels: string (nullable = true)\n",
      " |-- engine-location: string (nullable = true)\n",
      " |-- wheel-base: string (nullable = true)\n",
      " |-- length: string (nullable = true)\n",
      " |-- width: string (nullable = true)\n",
      " |-- height: string (nullable = true)\n",
      " |-- curb-weight: string (nullable = true)\n",
      " |-- engine-type: string (nullable = true)\n",
      " |-- num-of-cylinders: string (nullable = true)\n",
      " |-- engine-size: string (nullable = true)\n",
      " |-- fuel-system: string (nullable = true)\n",
      " |-- bore: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- compression-ratio: string (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- peak-rpm: string (nullable = true)\n",
      " |-- city-mpg: string (nullable = true)\n",
      " |-- highway-mpg: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "df_string = sqlContext.read.csv(SparkFiles.get(\"Automobile_data.csv\"), header=True, inferSchema=  True)\n",
    "df_string.printSchema()\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "# List of continuous features\n",
    "CONTI_FEATURES  = ['make', 'fuel-type','num-of-doors', 'aspiration', 'wheel-base', 'fuel-system']\n",
    "# Convert the type\n",
    "df_string = convertColumn(df_string, CONTI_FEATURES, FloatType())\n",
    "# Check the dataset\n",
    "df_string.printSchema()\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "#stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"newlabel\")\n",
    "#model = stringIndexer.fit(df)\n",
    "#df = model.transform(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|fuel-type|       make|\n",
      "+---------+-----------+\n",
      "|      gas|alfa-romero|\n",
      "|      gas|alfa-romero|\n",
      "|      gas|alfa-romero|\n",
      "|      gas|       audi|\n",
      "|      gas|       audi|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('fuel-type','make').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         make|count|\n",
      "+-------------+-----+\n",
      "|  alfa-romero|    3|\n",
      "|         audi|    7|\n",
      "|          bmw|    8|\n",
      "|    chevrolet|    3|\n",
      "|        dodge|    9|\n",
      "|        honda|   13|\n",
      "|        isuzu|    4|\n",
      "|       jaguar|    3|\n",
      "|        mazda|   17|\n",
      "|mercedes-benz|    8|\n",
      "|      mercury|    1|\n",
      "|   mitsubishi|   13|\n",
      "|       nissan|   18|\n",
      "|       peugot|   11|\n",
      "|     plymouth|    7|\n",
      "|      porsche|    5|\n",
      "|      renault|    2|\n",
      "|         saab|    6|\n",
      "|       subaru|   12|\n",
      "|       toyota|   32|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"make\").count().sort(\"make\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+------------------+------------------+-----------------+------------------+------------------+-----------+----------------+------------------+-----------+------------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+\n",
      "|summary|         symboling|normalized-losses|       make|fuel-type|aspiration|num-of-doors| body-style|drive-wheels|engine-location|        wheel-base|            length|            width|            height|       curb-weight|engine-type|num-of-cylinders|       engine-size|fuel-system|              bore|            stroke| compression-ratio|        horsepower|         peak-rpm|         city-mpg|      highway-mpg|             price|\n",
      "+-------+------------------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+------------------+------------------+-----------------+------------------+------------------+-----------+----------------+------------------+-----------+------------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+\n",
      "|  count|               205|              205|        205|      205|       205|         205|        205|         205|            205|               205|               205|              205|               205|               205|        205|             205|               205|        205|               205|               205|               205|               205|              205|              205|              205|               205|\n",
      "|   mean|0.8341463414634146|            122.0|       null|     null|      null|        null|       null|        null|           null| 98.75658536585378|174.04926829268305|65.90780487804875|53.724878048780525|2555.5658536585365|       null|            null|126.90731707317073|       null|3.3297512437810957|3.2554228855721337|10.142536585365855|104.25615763546799|5125.369458128079|25.21951219512195|30.75121951219512|13207.129353233831|\n",
      "| stddev|1.2453068281055295|35.44216753055326|       null|     null|      null|        null|       null|        null|           null|6.0217756850255695|12.337288526555188|2.145203852687182| 2.443521969904905| 520.6802035016384|       null|            null|41.642693438179855|       null|0.2735387318295989|0.3167174533770312|3.9720403218632985| 39.71436878679357|479.3345598334159| 6.54214165300162|6.886443130941823| 7947.066341939271|\n",
      "|    min|                -1|              101|alfa-romero|   diesel|       std|           ?|convertible|         4wd|          front|             100.4|             141.1|             60.3|              47.8|              1488|       dohc|           eight|               103|       1bbl|              2.54|              2.07|                10|               100|             4150|               13|               16|             10198|\n",
      "|    max|                 3|                ?|      volvo|      gas|     turbo|         two|      wagon|         rwd|           rear|              99.8|             208.1|             72.3|              59.8|              4066|      rotor|             two|                98|       spfi|                 ?|                 ?|               9.6|                 ?|                ?|               49|               54|                 ?|\n",
      "+-------+------------------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+------------------+------------------+-----------------+------------------+------------------+-----------+----------------+------------------+-----------+------------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|summary|engine-location|\n",
      "+-------+---------------+\n",
      "|  count|            205|\n",
      "|   mean|           null|\n",
      "| stddev|           null|\n",
      "|    min|          front|\n",
      "|    max|           rear|\n",
      "+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('engine-location').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder_ae9fa622b6bf\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "|symboling|normalized-losses|       make|fuel-type|aspiration|num-of-doors| body-style|drive-wheels|engine-location|wheel-base|length|width|height|curb-weight|engine-type|num-of-cylinders|engine-size|fuel-system|bore|stroke|compression-ratio|horsepower|peak-rpm|city-mpg|highway-mpg|price|make_encoded|       make_vec|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "|        3|                ?|alfa-romero|      gas|       std|         two|convertible|         rwd|          front|      88.6| 168.8| 64.1|  48.8|       2548|       dohc|            four|        130|       mpfi|3.47|  2.68|              9.0|       111|    5000|      21|         27|13495|        17.0|(21,[17],[1.0])|\n",
      "|        3|                ?|alfa-romero|      gas|       std|         two|convertible|         rwd|          front|      88.6| 168.8| 64.1|  48.8|       2548|       dohc|            four|        130|       mpfi|3.47|  2.68|              9.0|       111|    5000|      21|         27|16500|        17.0|(21,[17],[1.0])|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "\n",
    "url = \"Automobile_data.csv\"\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "\n",
    "sc.addFile(url)\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(SparkFiles.get(\"Automobile_data.csv\"), header=True, inferSchema= True)\n",
    "stringIndexer = StringIndexer(inputCol=\"make\", outputCol=\"make_encoded\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"make_encoded\", outputCol=\"make_vec\")\n",
    "print(encoder)\n",
    "encoded = encoder.fit(indexed).transform(indexed)\n",
    "encoded.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder_c9ab330325fa\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "|symboling|normalized-losses|       make|fuel-type|aspiration|num-of-doors| body-style|drive-wheels|engine-location|wheel-base|length|width|height|curb-weight|engine-type|num-of-cylinders|engine-size|fuel-system|bore|stroke|compression-ratio|horsepower|peak-rpm|city-mpg|highway-mpg|price|make_encoded|       make_vec|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "|        3|                ?|alfa-romero|      gas|       std|         two|convertible|         rwd|          front|      88.6| 168.8| 64.1|  48.8|       2548|       dohc|            four|        130|       mpfi|3.47|  2.68|              9.0|       111|    5000|      21|         27|13495|        17.0|(21,[17],[1.0])|\n",
      "|        3|                ?|alfa-romero|      gas|       std|         two|convertible|         rwd|          front|      88.6| 168.8| 64.1|  48.8|       2548|       dohc|            four|        130|       mpfi|3.47|  2.68|              9.0|       111|    5000|      21|         27|16500|        17.0|(21,[17],[1.0])|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------------+-----------+\n",
      "|         make|count(make)|\n",
      "+-------------+-----------+\n",
      "|       peugot|          7|\n",
      "|       jaguar|          3|\n",
      "|   mitsubishi|          8|\n",
      "|       toyota|         19|\n",
      "|         saab|          4|\n",
      "|     plymouth|          2|\n",
      "|         audi|          2|\n",
      "|          bmw|          5|\n",
      "|  alfa-romero|          2|\n",
      "|        dodge|          2|\n",
      "|        mazda|          7|\n",
      "|mercedes-benz|          6|\n",
      "|        isuzu|          2|\n",
      "|      porsche|          4|\n",
      "|    chevrolet|          2|\n",
      "|        honda|          4|\n",
      "|   volkswagen|          9|\n",
      "|      renault|          2|\n",
      "|       nissan|          8|\n",
      "|       subaru|          7|\n",
      "+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "\n",
    "url = \"Automobile_data.csv\"\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "\n",
    "sc.addFile(url)\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(SparkFiles.get(\"Automobile_data.csv\"), header=True, inferSchema= True)\n",
    "stringIndexer = StringIndexer(inputCol=\"make\", outputCol=\"make_encoded\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"make_encoded\", outputCol=\"make_vec\")\n",
    "print(encoder)\n",
    "encoded = encoder.fit(indexed).transform(indexed)\n",
    "encoded.show(2)\n",
    "#  Encode the categorical data\n",
    "\n",
    "CONTI_FEATURES  = ['make', 'fuel-type','aspiration', 'num-of-doors', 'body-style', 'drive-wheels']\n",
    "CATE_FEATURES = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'engine-type']\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()],\n",
    "                                     outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "#Index the label feature\n",
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx =  StringIndexer(inputCol=\"symboling\", outputCol=\"newlabel\")\n",
    "stages += [label_stringIdx]\n",
    "#Add continuos variable\n",
    "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTI_FEATURES\n",
    "#assemble the steps\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "df_remove = df.filter(df.symboling !='1')\n",
    "pipelineModel = pipeline.fit(df_remove)\n",
    "# model = pipelineModel.transform(df_remove)\n",
    "input_data = model.transform(df_remove)\n",
    "df_train = input_data\n",
    "train_data, test_data = df_train.randomSplit([.8,.2],seed=1234)\n",
    "train_data.groupby('make').agg({'make': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder_236e55122708\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "|symboling|normalized-losses|       make|fuel-type|aspiration|num-of-doors| body-style|drive-wheels|engine-location|wheel-base|length|width|height|curb-weight|engine-type|num-of-cylinders|engine-size|fuel-system|bore|stroke|compression-ratio|horsepower|peak-rpm|city-mpg|highway-mpg|price|make_encoded|       make_vec|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "|        3|                ?|alfa-romero|      gas|       std|         two|convertible|         rwd|          front|      88.6| 168.8| 64.1|  48.8|       2548|       dohc|            four|        130|       mpfi|3.47|  2.68|              9.0|       111|    5000|      21|         27|13495|        17.0|(21,[17],[1.0])|\n",
      "|        3|                ?|alfa-romero|      gas|       std|         two|convertible|         rwd|          front|      88.6| 168.8| 64.1|  48.8|       2548|       dohc|            four|        130|       mpfi|3.47|  2.68|              9.0|       111|    5000|      21|         27|16500|        17.0|(21,[17],[1.0])|\n",
      "+---------+-----------------+-----------+---------+----------+------------+-----------+------------+---------------+----------+------+-----+------+-----------+-----------+----------------+-----------+-----------+----+------+-----------------+----------+--------+--------+-----------+-----+------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------------+-----------+\n",
      "|         make|count(make)|\n",
      "+-------------+-----------+\n",
      "|       peugot|          7|\n",
      "|       jaguar|          3|\n",
      "|   mitsubishi|          8|\n",
      "|       toyota|         19|\n",
      "|         saab|          4|\n",
      "|     plymouth|          2|\n",
      "|         audi|          2|\n",
      "|          bmw|          5|\n",
      "|  alfa-romero|          2|\n",
      "|        dodge|          2|\n",
      "|        mazda|          7|\n",
      "|mercedes-benz|          6|\n",
      "|        isuzu|          2|\n",
      "|      porsche|          4|\n",
      "|    chevrolet|          2|\n",
      "|        honda|          4|\n",
      "|   volkswagen|          9|\n",
      "|      renault|          2|\n",
      "|       nissan|          8|\n",
      "|       subaru|          7|\n",
      "+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column peak-rpm must be of type struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-b86c0c185bad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;31m# Run cross validations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m \u001b[0mcvModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;31m# likely take a fair amount of time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hello-spark\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hello-spark\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\tuning.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\tuning.py\u001b[0m in \u001b[0;36msingleTask\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msingleTask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelIter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meva\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcollectSubModel\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No models remaining.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitSingleModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfitSingleModel\u001b[1;34m(index)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfitSingleModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparamMaps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_FitMultipleIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitSingleModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparamMaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hello-spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1305\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(e)\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Column peak-rpm must be of type struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually string."
     ]
    }
   ],
   "source": [
    "# BUILD THE LOGISTIC REGRESSOR\n",
    "import pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "url = \"Automobile_data.csv\"\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "\n",
    "sc.addFile(url)\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(SparkFiles.get(\"Automobile_data.csv\"), header=True, inferSchema= True)\n",
    "stringIndexer = StringIndexer(inputCol=\"make\", outputCol=\"make_encoded\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"make_encoded\", outputCol=\"make_vec\")\n",
    "print(encoder)\n",
    "encoded = encoder.fit(indexed).transform(indexed)\n",
    "encoded.show(2)\n",
    "#  Encode the categorical data\n",
    "\n",
    "CONTI_FEATURES  = ['make', 'fuel-type','aspiration', 'num-of-doors', 'body-style', 'drive-wheels']\n",
    "CATE_FEATURES = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'engine-type']\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()],\n",
    "                                     outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "#Index the label feature\n",
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx =  StringIndexer(inputCol=\"symboling\", outputCol=\"newlabel\")\n",
    "stages += [label_stringIdx]\n",
    "#Add continuos variable\n",
    "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTI_FEATURES\n",
    "#assemble the steps\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "df_remove = df.filter(df.symboling !='1')\n",
    "pipelineModel = pipeline.fit(df_remove)\n",
    "# model = pipelineModel.transform(df_remove)\n",
    "input_data = model.transform(df_remove)\n",
    "df_train = input_data\n",
    "train_data, test_data = df_train.randomSplit([.8,.2],seed=1234)\n",
    "train_data.groupby('make').agg({'make': 'count'}).show()\n",
    "# TODO: TO DISCUSS WITH GABRIEL WHAT CAN BE THE PROBLEM\n",
    "# Initialize `lr`\n",
    "# lr = LogisticRegression(labelCol=\"make\",\n",
    "#                         featuresCol=\"peak-rpm\",\n",
    "#                         maxIter=10,\n",
    "#                         regParam=0.3)\n",
    "\n",
    "# # Fit the data to the model\n",
    "# linearModel = lr.fit(test_data)\n",
    "# # Print the coefficients and intercept for logistic regression\n",
    "# print(\"Coefficients: \" + str(linearModel.coefficients))\n",
    "# print(\"Intercept: \" + str(linearModel.intercept))\n",
    "# # Make predictions on test data using the transform() method.\n",
    "# predictions = linearModel.transform(test_data)\n",
    "# selected = predictions.select(\"label\", \"prediction\", \"probability\")\n",
    "# selected.show(20)\n",
    "# cm = predictions.select(\"label\", \"prediction\")\n",
    "# cm.groupby('label').agg({'label': 'count'}).show()\n",
    "# cm.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "# cm.filter(cm.label == cm.prediction).count() / cm.count()\n",
    "# def accuracy_m(model): \n",
    "#     predictions = model.transform(test_data)\n",
    "#     cm = predictions.select(\"label\", \"prediction\")\n",
    "#     acc = cm.filter(cm.label == cm.prediction).count() / cm.count()\n",
    "#     print(\"Model accuracy: %.3f%%\" % (acc * 100)) \n",
    "# accuracy_m(model = linearModel)\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# predictions = model.transform(df)\n",
    "# # Evaluate model\n",
    "# evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"make\")\n",
    "# print(evaluator.evaluate(predictions))\n",
    "# print(evaluator.getMetricName())\n",
    "# print(evaluator.evaluate(predictions))\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5])\n",
    "             .build())\n",
    "from time import *\n",
    "start_time = time()\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_data)\n",
    "# likely take a fair amount of time\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train model: %.3f seconds\" % elapsed_time)\n",
    "accuracy_m(model = cvModel)\n",
    "bestModel = cvModel.bestModel\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
